import os
import hashlib
from PIL import Image
import imagehash
from collections import defaultdict
import argparse
from pathlib import Path
import json
from datetime import datetime
import sys

class PhotoDuplicateCleaner:
    """æ™ºèƒ½ç…§ç‰‡é‡è¤‡æª¢æ¸¬èˆ‡æ¸…ç†å·¥å…· - æ”¯æ´å¤šç›®éŒ„æ¯”å°"""

    def __init__(self, folder_paths, hash_size=8, similarity_threshold=5, recursive=True):
        """
        åˆå§‹åŒ–ç…§ç‰‡æ¸…ç†å·¥å…·

        Args:
            folder_paths (list): è¦æƒæçš„è³‡æ–™å¤¾è·¯å¾‘åˆ—è¡¨
            hash_size (int): é›œæ¹Šå¤§å°ï¼Œè¶Šå¤§è¶Šç²¾ç¢ºä½†é€Ÿåº¦è¼ƒæ…¢
            similarity_threshold (int): ç›¸ä¼¼åº¦é–¾å€¼ï¼Œæ•¸å€¼è¶Šå°è¶Šåš´æ ¼
            recursive (bool): æ˜¯å¦éè¿´æƒæå­ç›®éŒ„
        """
        self.folder_paths = [Path(path) for path in folder_paths]
        self.hash_size = hash_size
        self.similarity_threshold = similarity_threshold
        self.recursive = recursive
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}
        self.photo_hashes = {}
        self.duplicate_groups = []
        self.folder_stats = {}

    def get_image_info(self, image_path):
        """ç²å–åœ–ç‰‡åŸºæœ¬è³‡è¨Š"""
        try:
            with Image.open(image_path) as img:
                width, height = img.size
                file_size = os.path.getsize(image_path)
                resolution = width * height

                # ç¢ºå®šç…§ç‰‡æ‰€å±¬çš„åŸå§‹æƒæç›®éŒ„
                source_folder = self.get_source_folder(image_path)

                return {
                    'path': image_path,
                    'width': width,
                    'height': height,
                    'resolution': resolution,
                    'file_size': file_size,
                    'format': img.format,
                    'source_folder': source_folder,
                    'relative_path': image_path.relative_to(source_folder) if source_folder else image_path
                }
        except Exception as e:
            print(f"ç„¡æ³•è™•ç†åœ–ç‰‡ {image_path}: {e}")
            return None

    def get_source_folder(self, image_path):
        """ç¢ºå®šåœ–ç‰‡æ‰€å±¬çš„åŸå§‹æƒæç›®éŒ„"""
        for folder in self.folder_paths:
            try:
                image_path.relative_to(folder)
                return folder
            except ValueError:
                continue
        return None

    def calculate_perceptual_hash(self, image_path):
        """è¨ˆç®—æ„ŸçŸ¥é›œæ¹Šå€¼"""
        try:
            with Image.open(image_path) as img:
                # ä½¿ç”¨å¤šç¨®é›œæ¹Šç®—æ³•æé«˜æº–ç¢ºæ€§
                phash = imagehash.phash(img, hash_size=self.hash_size)
                dhash = imagehash.dhash(img, hash_size=self.hash_size)
                whash = imagehash.whash(img, hash_size=self.hash_size)

                return {
                    'phash': phash,
                    'dhash': dhash,
                    'whash': whash
                }
        except Exception as e:
            print(f"ç„¡æ³•è¨ˆç®—é›œæ¹Šå€¼ {image_path}: {e}")
            return None

    def scan_photos(self):
        """æƒææ‰€æœ‰æŒ‡å®šè³‡æ–™å¤¾ä¸­çš„ç…§ç‰‡"""
        print(f"é–‹å§‹æƒæ {len(self.folder_paths)} å€‹è³‡æ–™å¤¾:")
        for folder in self.folder_paths:
            print(f"  - {folder}")

        total_files = 0
        processed_count = 0

        # åˆå§‹åŒ–å„è³‡æ–™å¤¾çµ±è¨ˆ
        for folder in self.folder_paths:
            self.folder_stats[str(folder)] = {
                'total_photos': 0,
                'processed_photos': 0,
                'total_size': 0,
                'exists': folder.exists()
            }

        # æƒææ¯å€‹è³‡æ–™å¤¾
        for folder_path in self.folder_paths:
            if not folder_path.exists():
                print(f"âš ï¸  è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
                continue

            print(f"\nğŸ“ æƒæè³‡æ–™å¤¾: {folder_path}")

            # æ ¹æ“šæ˜¯å¦éè¿´é¸æ“‡æƒææ–¹å¼
            if self.recursive:
                print(f"   (åŒ…å«æ‰€æœ‰å­ç›®éŒ„)")
                photo_files = []
                for ext in self.supported_formats:
                    photo_files.extend(folder_path.rglob(f"*{ext}"))
                    photo_files.extend(folder_path.rglob(f"*{ext.upper()}"))
            else:
                print(f"   (åƒ…æƒæç•¶å‰ç›®éŒ„)")
                photo_files = []
                for ext in self.supported_formats:
                    photo_files.extend(folder_path.glob(f"*{ext}"))
                    photo_files.extend(folder_path.glob(f"*{ext.upper()}"))

            folder_file_count = len(photo_files)
            total_files += folder_file_count
            self.folder_stats[str(folder_path)]['total_photos'] = folder_file_count

            print(f"   æ‰¾åˆ° {folder_file_count} å¼µç…§ç‰‡")

            # è™•ç†è©²è³‡æ–™å¤¾ä¸­çš„ç…§ç‰‡
            folder_processed = 0
            for photo_path in photo_files:
                info = self.get_image_info(photo_path)
                if info:
                    hashes = self.calculate_perceptual_hash(photo_path)
                    if hashes:
                        info['hashes'] = hashes
                        self.photo_hashes[str(photo_path)] = info
                        processed_count += 1
                        folder_processed += 1
                        self.folder_stats[str(folder_path)]['total_size'] += info['file_size']

                if processed_count % 50 == 0:
                    print(f"   å·²è™•ç† {processed_count} å¼µç…§ç‰‡...")

            self.folder_stats[str(folder_path)]['processed_photos'] = folder_processed
            print(f"   âœ… æˆåŠŸè™•ç† {folder_processed} å¼µç…§ç‰‡")

        print(f"\nğŸ“Š æƒæç¸½çµ:")
        print(f"   ç¸½å…±æ‰¾åˆ°: {total_files} å¼µç…§ç‰‡")
        print(f"   æˆåŠŸè™•ç†: {processed_count} å¼µç…§ç‰‡")
        self.display_folder_stats()

    def display_folder_stats(self):
        """é¡¯ç¤ºå„è³‡æ–™å¤¾çµ±è¨ˆè³‡è¨Š"""
        print(f"\nğŸ“ˆ å„è³‡æ–™å¤¾çµ±è¨ˆ:")
        print("-" * 80)

        for folder_path, stats in self.folder_stats.items():
            if not stats['exists']:
                print(f"âŒ {folder_path}: è³‡æ–™å¤¾ä¸å­˜åœ¨")
                continue

            size_mb = stats['total_size'] / 1024 / 1024
            print(f"ğŸ“ {Path(folder_path).name}:")
            print(f"   è·¯å¾‘: {folder_path}")
            print(f"   ç…§ç‰‡æ•¸é‡: {stats['processed_photos']} å¼µ")
            print(f"   ç¸½å¤§å°: {size_mb:.2f} MB")
            print()

    def find_duplicates(self):
        """æ‰¾å‡ºé‡è¤‡çš„ç…§ç‰‡ç¾¤çµ„"""
        print("ğŸ” é–‹å§‹æ¯”å°é‡è¤‡ç…§ç‰‡...")

        photo_list = list(self.photo_hashes.values())
        grouped_photos = defaultdict(list)
        processed_pairs = set()

        total_comparisons = len(photo_list) * (len(photo_list) - 1) // 2
        current_comparison = 0

        for i, photo1 in enumerate(photo_list):
            for j, photo2 in enumerate(photo_list[i+1:], i+1):
                current_comparison += 1

                # é¡¯ç¤ºé€²åº¦
                if current_comparison % 1000 == 0:
                    progress = (current_comparison / total_comparisons) * 100
                    print(f"   æ¯”å°é€²åº¦: {progress:.1f}% ({current_comparison}/{total_comparisons})")

                pair_key = tuple(sorted([str(photo1['path']), str(photo2['path'])]))
                if pair_key in processed_pairs:
                    continue
                processed_pairs.add(pair_key)

                if self.are_similar(photo1['hashes'], photo2['hashes']):
                    # ä½¿ç”¨è¼ƒå°çš„é›œæ¹Šå€¼ä½œç‚ºç¾¤çµ„éµ
                    group_key = min(str(photo1['hashes']['phash']), str(photo2['hashes']['phash']))
                    grouped_photos[group_key].extend([photo1, photo2])

        # å»é™¤é‡è¤‡é …ç›®ä¸¦æ•´ç†ç¾¤çµ„
        final_groups = []
        for group in grouped_photos.values():
            # å»é™¤é‡è¤‡çš„ç…§ç‰‡é …ç›®
            unique_photos = {}
            for photo in group:
                path_key = str(photo['path'])
                if path_key not in unique_photos:
                    unique_photos[path_key] = photo

            if len(unique_photos) > 1:
                final_groups.append(list(unique_photos.values()))

        self.duplicate_groups = final_groups
        print(f"âœ… æ‰¾åˆ° {len(final_groups)} å€‹é‡è¤‡ç…§ç‰‡ç¾¤çµ„")

        # çµ±è¨ˆè·¨è³‡æ–™å¤¾é‡è¤‡
        self.analyze_cross_folder_duplicates()

    def analyze_cross_folder_duplicates(self):
        """åˆ†æè·¨è³‡æ–™å¤¾é‡è¤‡æƒ…æ³"""
        cross_folder_groups = 0
        same_folder_groups = 0

        for group in self.duplicate_groups:
            source_folders = set(str(photo['source_folder']) for photo in group)
            if len(source_folders) > 1:
                cross_folder_groups += 1
            else:
                same_folder_groups += 1

        print(f"\nğŸ“Š é‡è¤‡é¡å‹åˆ†æ:")
        print(f"   è·¨è³‡æ–™å¤¾é‡è¤‡: {cross_folder_groups} å€‹ç¾¤çµ„")
        print(f"   åŒè³‡æ–™å¤¾é‡è¤‡: {same_folder_groups} å€‹ç¾¤çµ„")

    def are_similar(self, hashes1, hashes2):
        """åˆ¤æ–·å…©å¼µç…§ç‰‡æ˜¯å¦ç›¸ä¼¼"""
        # ä½¿ç”¨å¤šç¨®é›œæ¹Šç®—æ³•é€²è¡Œæ¯”è¼ƒï¼Œæé«˜æº–ç¢ºæ€§
        phash_diff = hashes1['phash'] - hashes2['phash']
        dhash_diff = hashes1['dhash'] - hashes2['dhash']
        whash_diff = hashes1['whash'] - hashes2['whash']

        # å¦‚æœä»»ä¸€ç¨®é›œæ¹Šç®—æ³•èªç‚ºç›¸ä¼¼ï¼Œå‰‡åˆ¤å®šç‚ºç›¸ä¼¼
        return (phash_diff <= self.similarity_threshold or
                dhash_diff <= self.similarity_threshold or
                whash_diff <= self.similarity_threshold)

    def generate_deletion_list(self):
        """ç”Ÿæˆå¾…åˆªé™¤æ¸…å–®ï¼Œæ”¯æ´å¤šç¨®ä¿ç•™ç­–ç•¥"""
        deletion_list = []
        keep_list = []

        for group in self.duplicate_groups:
            # æŒ‰è§£æåº¦æ’åºï¼Œè§£æåº¦ç›¸åŒæ™‚æŒ‰æª”æ¡ˆå¤§å°æ’åº
            sorted_group = sorted(group, key=lambda x: (x['resolution'], x['file_size']), reverse=True)

            # ä¿ç•™è§£æåº¦æœ€é«˜çš„ç…§ç‰‡
            keep_photo = sorted_group[0]
            keep_list.append(keep_photo)

            # å…¶é¤˜åŠ å…¥åˆªé™¤æ¸…å–®
            for photo in sorted_group[1:]:
                deletion_list.append(photo)

        return deletion_list, keep_list

    def display_deletion_preview(self, deletion_list, keep_list):
        """é¡¯ç¤ºåˆªé™¤é è¦½ï¼ŒåŒ…å«è·¨è³‡æ–™å¤¾è³‡è¨Š"""
        print("\n" + "="*100)
        print("é‡è¤‡ç…§ç‰‡æ¸…ç†é è¦½")
        print("="*100)

        total_space_saved = 0
        cross_folder_deletions = 0

        for i, group in enumerate(self.duplicate_groups, 1):
            print(f"\nç¾¤çµ„ {i} (å…± {len(group)} å¼µé‡è¤‡ç…§ç‰‡):")
            print("-" * 80)

            # æª¢æŸ¥æ˜¯å¦ç‚ºè·¨è³‡æ–™å¤¾é‡è¤‡
            source_folders = set(str(photo['source_folder']) for photo in group)
            if len(source_folders) > 1:
                print(f"ğŸ”„ è·¨è³‡æ–™å¤¾é‡è¤‡ (æ¶‰åŠ {len(source_folders)} å€‹è³‡æ–™å¤¾)")
                cross_folder_deletions += 1
            else:
                print(f"ğŸ“ åŒè³‡æ–™å¤¾é‡è¤‡")

            # æ‰¾å‡ºé€™å€‹ç¾¤çµ„ä¸­è¦ä¿ç•™å’Œåˆªé™¤çš„ç…§ç‰‡
            group_paths = {str(photo['path']) for photo in group}
            group_keep = [p for p in keep_list if str(p['path']) in group_paths]
            group_delete = [p for p in deletion_list if str(p['path']) in group_paths]

            # é¡¯ç¤ºä¿ç•™çš„ç…§ç‰‡
            if group_keep:
                keep_photo = group_keep[0]
                folder_name = Path(keep_photo['source_folder']).name if keep_photo['source_folder'] else "æœªçŸ¥"
                print(f"âœ… ä¿ç•™: {keep_photo['relative_path']}")
                print(f"   ğŸ“ è³‡æ–™å¤¾: {folder_name}")
                print(f"   ğŸ“ è§£æåº¦: {keep_photo['width']}x{keep_photo['height']} ({keep_photo['resolution']:,} åƒç´ )")
                print(f"   ğŸ’¾ æª”æ¡ˆå¤§å°: {keep_photo['file_size']:,} bytes")

            # é¡¯ç¤ºè¦åˆªé™¤çš„ç…§ç‰‡
            for photo in group_delete:
                folder_name = Path(photo['source_folder']).name if photo['source_folder'] else "æœªçŸ¥"
                print(f"âŒ åˆªé™¤: {photo['relative_path']}")
                print(f"   ğŸ“ è³‡æ–™å¤¾: {folder_name}")
                print(f"   ğŸ“ è§£æåº¦: {photo['width']}x{photo['height']} ({photo['resolution']:,} åƒç´ )")
                print(f"   ğŸ’¾ æª”æ¡ˆå¤§å°: {photo['file_size']:,} bytes")
                total_space_saved += photo['file_size']

        print(f"\nğŸ“Š ç¸½è¨ˆ:")
        print(f"   å°‡åˆªé™¤: {len(deletion_list)} å¼µé‡è¤‡ç…§ç‰‡")
        print(f"   å°‡ä¿ç•™: {len(keep_list)} å¼µé«˜è§£æåº¦ç…§ç‰‡")
        print(f"   è·¨è³‡æ–™å¤¾é‡è¤‡ç¾¤çµ„: {cross_folder_deletions} å€‹")
        print(f"   é è¨ˆç¯€çœç©ºé–“: {total_space_saved:,} bytes ({total_space_saved/1024/1024:.2f} MB)")

        # æŒ‰è³‡æ–™å¤¾é¡¯ç¤ºåˆªé™¤çµ±è¨ˆ
        self.display_deletion_by_folder(deletion_list)

    def display_deletion_by_folder(self, deletion_list):
        """æŒ‰è³‡æ–™å¤¾é¡¯ç¤ºåˆªé™¤çµ±è¨ˆ"""
        folder_deletions = defaultdict(list)

        for photo in deletion_list:
            folder_key = str(photo['source_folder']) if photo['source_folder'] else "æœªçŸ¥"
            folder_deletions[folder_key].append(photo)

        print(f"\nğŸ“ å„è³‡æ–™å¤¾åˆªé™¤çµ±è¨ˆ:")
        print("-" * 60)

        for folder_path, photos in folder_deletions.items():
            folder_name = Path(folder_path).name if folder_path != "æœªçŸ¥" else "æœªçŸ¥"
            total_size = sum(photo['file_size'] for photo in photos)
            print(f"ğŸ“ {folder_name}: {len(photos)} å¼µç…§ç‰‡, {total_size/1024/1024:.2f} MB")

    def save_deletion_log(self, deletion_list, log_file="deletion_log.json"):
        """å„²å­˜åˆªé™¤è¨˜éŒ„"""
        # æŒ‰è³‡æ–™å¤¾åˆ†çµ„è¨˜éŒ„
        folder_groups = defaultdict(list)
        for photo in deletion_list:
            folder_key = str(photo['source_folder']) if photo['source_folder'] else "unknown"
            folder_groups[folder_key].append({
                'path': str(photo['path']),
                'relative_path': str(photo['relative_path']),
                'resolution': f"{photo['width']}x{photo['height']}",
                'file_size': photo['file_size']
            })

        log_data = {
            'timestamp': datetime.now().isoformat(),
            'scan_folders': [str(folder) for folder in self.folder_paths],
            'recursive_scan': self.recursive,
            'settings': {
                'hash_size': self.hash_size,
                'similarity_threshold': self.similarity_threshold
            },
            'deletion_by_folder': dict(folder_groups),
            'summary': {
                'total_deleted': len(deletion_list),
                'total_space_saved': sum(photo['file_size'] for photo in deletion_list),
                'folders_affected': len(folder_groups)
            }
        }

        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“ åˆªé™¤è¨˜éŒ„å·²å„²å­˜è‡³: {log_file}")

    def delete_photos(self, deletion_list):
        """åŸ·è¡Œç…§ç‰‡åˆªé™¤"""
        print(f"\nğŸ—‘ï¸  é–‹å§‹åˆªé™¤ {len(deletion_list)} å¼µç…§ç‰‡...")

        deleted_count = 0
        failed_deletions = []
        deleted_by_folder = defaultdict(int)

        for photo in deletion_list:
            try:
                os.remove(photo['path'])
                deleted_count += 1
                folder_key = str(photo['source_folder']) if photo['source_folder'] else "unknown"
                deleted_by_folder[folder_key] += 1
                print(f"âœ… å·²åˆªé™¤: {photo['relative_path']}")
            except Exception as e:
                failed_deletions.append((photo['path'], str(e)))
                print(f"âŒ åˆªé™¤å¤±æ•—: {photo['relative_path']} - {e}")

        print(f"\nğŸ“Š åˆªé™¤å®Œæˆ:")
        print(f"   æˆåŠŸåˆªé™¤: {deleted_count} å¼µç…§ç‰‡")

        # é¡¯ç¤ºå„è³‡æ–™å¤¾åˆªé™¤çµæœ
        for folder_path, count in deleted_by_folder.items():
            folder_name = Path(folder_path).name if folder_path != "unknown" else "æœªçŸ¥"
            print(f"   ğŸ“ {folder_name}: {count} å¼µ")

        if failed_deletions:
            print(f"   åˆªé™¤å¤±æ•—: {len(failed_deletions)} å¼µç…§ç‰‡")
            for path, error in failed_deletions:
                print(f"     {path}: {error}")

    def run(self):
        """åŸ·è¡Œå®Œæ•´çš„æ¸…ç†æµç¨‹"""
        print("ğŸ–¼ï¸  æ™ºèƒ½ç…§ç‰‡é‡è¤‡æª¢æ¸¬èˆ‡æ¸…ç†å·¥å…· (å¤šç›®éŒ„ç‰ˆ)")
        print("="*70)

        # æª¢æŸ¥è³‡æ–™å¤¾å­˜åœ¨æ€§
        valid_folders = [folder for folder in self.folder_paths if folder.exists()]
        if not valid_folders:
            print("âŒ éŒ¯èª¤: æ‰€æœ‰æŒ‡å®šçš„è³‡æ–™å¤¾éƒ½ä¸å­˜åœ¨")
            return

        if len(valid_folders) < len(self.folder_paths):
            missing_folders = [folder for folder in self.folder_paths if not folder.exists()]
            print(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œå°‡è¢«è·³é:")
            for folder in missing_folders:
                print(f"   - {folder}")

        # æ­¥é©Ÿ1: æƒæç…§ç‰‡
        self.scan_photos()

        if not self.photo_hashes:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯è™•ç†çš„ç…§ç‰‡")
            return

        # æ­¥é©Ÿ2: æ‰¾å‡ºé‡è¤‡é …ç›®
        self.find_duplicates()

        if not self.duplicate_groups:
            print("âœ… æœªç™¼ç¾é‡è¤‡ç…§ç‰‡")
            return

        # æ­¥é©Ÿ3: ç”Ÿæˆåˆªé™¤æ¸…å–®
        deletion_list, keep_list = self.generate_deletion_list()

        # æ­¥é©Ÿ4: é¡¯ç¤ºé è¦½
        self.display_deletion_preview(deletion_list, keep_list)

        # æ­¥é©Ÿ5: ç¢ºèªåŸ·è¡Œ
        print(f"\nâ“ æ˜¯å¦ç¢ºå®šåŸ·è¡Œåˆªé™¤æ“ä½œ? (è¼¸å…¥ 'yes' ç¢ºèª, å…¶ä»–ä»»ä½•è¼¸å…¥å–æ¶ˆ)")
        confirmation = input("è«‹è¼¸å…¥: ").strip().lower()

        if confirmation == 'yes':
            # å„²å­˜åˆªé™¤è¨˜éŒ„
            self.save_deletion_log(deletion_list)

            # åŸ·è¡Œåˆªé™¤
            self.delete_photos(deletion_list)
            print("\nğŸ‰ æ¸…ç†å®Œæˆ!")
        else:
            print("âŒ æ“ä½œå·²å–æ¶ˆ")


def main():
    parser = argparse.ArgumentParser(
        description='æ™ºèƒ½ç…§ç‰‡é‡è¤‡æª¢æ¸¬èˆ‡æ¸…ç†å·¥å…· (å¤šç›®éŒ„ç‰ˆ)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # æƒæå–®ä¸€è³‡æ–™å¤¾
  python photo_cleaner.py ~/Pictures

  # æƒæå¤šå€‹è³‡æ–™å¤¾
  python photo_cleaner.py ~/Pictures ~/Downloads/Photos ~/Desktop/Images

  # ä¸éè¿´æƒæå­ç›®éŒ„
  python photo_cleaner.py ~/Pictures --no-recursive

  # è‡ªè¨‚åƒæ•¸
  python photo_cleaner.py ~/Pictures ~/Downloads --hash-size 16 --threshold 3
        """
    )

    parser.add_argument('folders', nargs='+', help='è¦æƒæçš„è³‡æ–™å¤¾è·¯å¾‘ (æ”¯æ´å¤šå€‹)')
    parser.add_argument('--hash-size', type=int, default=8,
                       help='é›œæ¹Šå¤§å° (é è¨­: 8, å»ºè­°ç¯„åœ: 4-16)')
    parser.add_argument('--threshold', type=int, default=5,
                       help='ç›¸ä¼¼åº¦é–¾å€¼ (é è¨­: 5, å»ºè­°ç¯„åœ: 3-10)')
    parser.add_argument('--no-recursive', action='store_true',
                       help='ä¸éè¿´æƒæå­ç›®éŒ„ (é è¨­æœƒæƒææ‰€æœ‰å­ç›®éŒ„)')

    args = parser.parse_args()

    cleaner = PhotoDuplicateCleaner(
        folder_paths=args.folders,
        hash_size=args.hash_size,
        similarity_threshold=args.threshold,
        recursive=not args.no_recursive
    )

    cleaner.run()


if __name__ == "__main__":
    # å¦‚æœç›´æ¥åŸ·è¡Œè…³æœ¬ï¼Œä½¿ç”¨äº’å‹•æ¨¡å¼
    if len(sys.argv) == 1:
        print("ğŸ–¼ï¸  æ™ºèƒ½ç…§ç‰‡é‡è¤‡æª¢æ¸¬èˆ‡æ¸…ç†å·¥å…· (å¤šç›®éŒ„ç‰ˆ)")
        print("="*70)

        # è¼¸å…¥å¤šå€‹è³‡æ–™å¤¾è·¯å¾‘
        print("ğŸ“ è«‹è¼¸å…¥è¦æƒæçš„è³‡æ–™å¤¾è·¯å¾‘ (å¯è¼¸å…¥å¤šå€‹ï¼Œç”¨ç©ºæ ¼åˆ†éš”):")
        folder_input = input("è³‡æ–™å¤¾è·¯å¾‘: ").strip()

        if not folder_input:
            print("âŒ æœªè¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘")
            exit(1)

        # è§£æå¤šå€‹è·¯å¾‘
        folder_paths = [path.strip().strip('"\'') for path in folder_input.split()]

        # è©¢å•æ˜¯å¦éè¿´æƒæ
        recursive_input = input("æ˜¯å¦æƒæå­ç›®éŒ„? (y/N): ").strip().lower()
        recursive = recursive_input in ['y', 'yes', 'æ˜¯']

        # è©¢å•é€²éšè¨­å®š
        print("\nâš™ï¸  é€²éšè¨­å®š (ç›´æ¥æŒ‰ Enter ä½¿ç”¨é è¨­å€¼):")
        hash_size_input = input("é›œæ¹Šå¤§å° (é è¨­ 8): ").strip()
        threshold_input = input("ç›¸ä¼¼åº¦é–¾å€¼ (é è¨­ 5): ").strip()

        hash_size = int(hash_size_input) if hash_size_input.isdigit() else 8
        threshold = int(threshold_input) if threshold_input.isdigit() else 5

        print(f"\nğŸš€ é–‹å§‹è™•ç† {len(folder_paths)} å€‹è³‡æ–™å¤¾...")

        cleaner = PhotoDuplicateCleaner(
            folder_paths=folder_paths,
            hash_size=hash_size,
            similarity_threshold=threshold,
            recursive=recursive
        )

        cleaner.run()
    else:
        main()
